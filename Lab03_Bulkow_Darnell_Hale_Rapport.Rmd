---
title: "Lab 3: Reducing Crime"
subtitle: "w203 Summer 2018"
author: "Madeleine Bulkow, Kim Darnell, Alla Hale, Emily Rapport"
date: \today
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
# Import car package
library(car)
```

## 1. Introduction
As advisees to political campaigns for statewide office in North Carolina, we believe that the crime rate across the state should be of central concern to any candidate.  Local governments desire to control the crime rate, and rigorous data analysis is needed to understand the role of crime in different parts of the state. This report examines the available crime data and attempts to answer the following research question: What variables are associated with crime rates across counties in North Carolina?  Based on this analysis, we generate several policy suggestions applicable to government officials in North Carolina for the late 1980s.

## 2. Data Definitions and Data Cleaning
The data analyzed in this report were collected as part of a multi-year study on crime by Cornwell and Trumball, originally published in 1994. The data include factors related to crime, demographics, and the economy for 90 of the 100 counties in North Carolina. For reasons of access, this report will focus exculsively on the data from 1987. 
 
The dataset includes the following variables, which we present with definitions and assumptions:

*county*: integer code representing which county the row represents. We received the data with these identifier codes in place of county names, so we cannot identify the individual counties in the dataset.

*year*: 1987 for all data points. 

*crmrte*: ratio of crimes permitted to population, taken from the FBI's Uniform Crime Reports.

*prbarr*: ratio of arrests to offenses, taken from the FBI's Uniform Crime Reports.

*prbconv*: ratio of convictions to arrests. Arrest data is taken from the FBI's Uniform Crime Reports, while conviction data is taken from the North Carolina Department of Correction.

*prbpris*: ratio of prison sentences to convictions, taken from the North Carolina Department of Correction.

*avgsen*: average prison sentence in days, which we believe is taken from the North Carolina Department of Correction.

*polpc*: police per capita, computed using the FBI's police agency employee counts.

*density*: people per square mile

*taxpc*: tax revenue per capita. 

*west*: indicator code specifying whether county is in Western North Carolina (1 if yes, 0 if no).

*central*: indicator code specifying whether county is in Central North Carolina (1 if yes, 0 if no).

*urban*: indicator code specifying whether county is urban, defined by whether the county is in a Standard Metropolitan Statistical Area as defined by the US Census. 

*pctmin80*: percentage of population that belongs to minority racial group, as taken by the 1980 US Census.

*mix*: ratio of face-to-face offenses to other offenses.

*pctymle*: percent young male, defined as proportion of population that is male between the ages of 15 and 24, as taken by US Census data. 

The remaining variables represent weekly wages in particular industries, as provided by the North Carolina Employment Security Commission:
- *wcon*: construction
- *wtuc*: transit, utilities, and communication
- *wtrd*: wholesale, retail trade
- *wfir*: finance, insurance, real estate
- *wser*: service industry
- *wmfg*: manufacturing
- *wfed*: federal employees
- *wsta*: state employees
- *wloc*: local government employees
 
We start by evaluating the available data, cleaning it by removing anomolous values, and perhaps transforming the data.  
```{r}
# Import the data
df = read.csv("crime_v2.csv")
#summary(df)
```

In the original dataset, there are several variables, including *prbarr*, *prbpris*, and *pctymle* that represent probabilities and are given as decimal values between 0-1. To facilitate comparing the coefficients for these variables more easily with other numerical values, we converted them to percentages between 0-100.  We note that there is one county, Madison County (FIPS code 115), for which the *prbarr* value post-conversion is greater than 100%. This could reflect an error in data gathering or recording, but it may also reflect that it is common for indviduals in this county to be arrested with greater frequency than they commit specific offenses.

In the case of *prbconv*, several of the original values are greater than 1. Although this may seem anomalous, it reflects the fact that the "probablity of conviction" is more effectively described as a ratio of the number of convictions per arrest, rather than as a probability of being convicted following arrest. Given that one might not be arrested for all crimes that one is subsequently convicted of, it makes sense that these numbers have a greater range than a traditional probabilities.

The variable *mix* also appears as values between 0-1 in the original dataset.  We converted the values for this variable to percentages to make their scale more consistent with the rest of the data.

To facilitate discussion of the variable *polpc*, we converted it from number of police per capita in a county to number of police per 1000 residents of a county.  That is, it is simply clearer to say, "There are 4 police officers per 1000 residents" than "There is .004 of a police officer per resident".

In the original dataset, the values for Wilkes Country (FIPS code 193) are given twice.  We removed one. In addition, there were six rows in that had no values for any variable. We removed all of these.

Data were not provided for the following counties (FIPS county codes are provide in parentheses): Camden (29), Carteret (31), Clay (43), Gates (73), Graham (75), Hyde (95), Jones (103), Mitchell (121), Tyrrell (177), and Yancey (199).  We do not know why these cases were omitted from the original dataset, nor can we say the extent to which the omission of 1/10 counties across the state might affect the effectiveness of our recommendations. However, a review of 2012 population estimates for the omitted counties indicate that 9/10 are ranked between 86-100 of the 100 counties in overall population. The remaining omitted county is ranked 37th overall in population in the state.  The generally low population rates for the omitted counties may indicate that there was insufficient crime data to include them in the dataset.

```{r}
# Clean the data

## NOTE FROM ALLA: This is just what I did to clean the data.  I am sure this can be done in a more efficient way.  Please just let me know what the final df is called so that I can update it in my models.
df_calc <- df

# Convert the prbarr, prbpris, and pctymle variables from decimals to percentages
df_calc$prbarr <- df$prbarr * 100
df_calc$prbpris <- df$prbpris * 100
df_calc$pctymle <- df$pctymle * 100


# Convert the mix variable from decimals to percentage
df_calc$mix <- df$mix * 100

# Convert the polpc variable from decimals to number of police per 1000 people
df_calc$polpc <- df$polpc * 1000

# Convert the prbconv variable from integer to numeric
df_calc$prbconv <- as.numeric(levels(df$prbconv)[df$prbconv])


#summary(df_calc)

#remove row 89, which is a duplicate of row 88 (Madison County, FIPS 193)
df_clean <- df_calc[-c(89), ]

#remove rows with no data (i.e., all NA values)
df_clean <- df_clean[-c(91:97), ]

#remove 
#df_clean <-df_calc[with(df_calc, prbarr <= 100 & wser <= 2000),]
```

##3. Building Models
Our central goal for this analysis is to determine what variables are most associated with crime across the state of North Carolina. For this reason, we will  use the *crmrte* variable as the outcome variable for our models. To begin, we examine our outcome variable.

```{r}
summary(df_clean$crmrte)
length(df_clean$crmrte)
```

The value of *crmrte* ranges from approximately .6% to 9.9%, with a mean of approximately 3.4%. There are 90 total cases and no missing cases. A histogram of the data, shown below, reveals that the crime rate data are positively skewed, with the majority of counties having a crime rate between 1-4%.  The extended right tail indicates that a few counties have substantially higher crime rates, with some between 8-10%.

```{r fig.height=3, fig.width=5}
hist(df_clean$crmrte, 
     main="County Crime Rates in 1987 North Carolina", 
     xlab= "Crimes Committed per Person", 
     ylab= "Number of Counties")
```


Given the relative perceived severity of face-to-face crimes over non-face-to-face crimes, it is useful to consider only the face-to-face crime rate. This can be found using the overall crime rate and the mix variable, which we recall contains the fraction of face-to-face crimes to other crimes. After making the fairly safe assumption that face-to-face $+$ other $=$ total crime, a somewhat tortuous manipulation gives us what we need: the ratio of face-to-face crimes among all crimes committed in a county.

\begin{align}
\frac{\text{face-to-face}}{\text{total}} &= 1 - \frac{\text{other}}{\text{total}} \\
&= 1 - \frac{\text{other}}{\text{face-to-face}+\text{other}} \\
&= 1 - \frac{1}{\frac{\text{face-to-face}+\text{other}}{\text{other}}}\\
&= 1 - \frac{1}{\frac{\text{face-to-face}}{\text{other}}+1}\\
&= 1 - \frac{1}{\text{mix}+1}
\end{align}

Now when multiplied with the overall crime rate, this gives the face-to-face crime rate in each county.

```{r fig.height=3, fig.width=5}
# Calculate the face-to-face crime rate
ftfcrmrte <- df_clean$crmrte * (1-1/(df_clean$mix+1))
# Examine the distribution
summary(ftfcrmrte)
hist(ftfcrmrte, 
     main="County Crime Rates in 1987 North Carolina", 
     xlab= "Crimes Committed per Person", 
     ylab= "Number of Counties")
```

The distribution of the face-to-face crime rate is similar, but not identical to, the base crime rate. The mean is lower, as we would expect, but only slightly lower, and values now range from .5% to 9.3%. The effect of this manipulation appears to be fairly small, so we will remain with the simpler crime rate for the majority of our models. At the end, to examine whether the causes of face-to-face crime might be different from the causes of crime overall, we will briefly examine this in a seperate model. 

## 4. The Models

We will engage the model building process in five stages, resulting in five separate models.  

The first four models are linear regressions of crime rate against an increasing numbers of predictive variables.  Model 1 includes only the variables we believe to be the main predictors of crime rate: population density (*density*), tax per capita (*taxpc*), and percentage of young males in the population (*pctymle*).  Model 2 includes the factors from Model 1 as well as several others that we believe contribute meaningfully to crime rate, including location in the state, the number of police per 1000 residents (*polpc*), the probability of being arrested (*prbarr*), and the probability of being convicted if arrested (*prbconv*).  Model 3 builds on Model 2 by adding information about the percentage of minorties (*pctmin80*), the probability of getting a prison sentence (*prbpris*), and the average length of sentence (*avgsen*).  In Model 4, we include all available variables, including those of questionable merit.  


For each of these models, we intend a classic linear model with the following assumptions: Assumption 1, linearity in parameters, holds, as each fit model has slope coefficients that are linear multipliers of the associated predictor variables. Assumption 2, random sampling, says that are data points must be independent and identically distributed. We have data for 97 of North Carolina's 100 counties (89 after remove NA values). While this represents something closer to the population of counties than a sample, we should be okay on the random sampling assumption if we assume that there is no pattern to the counties that weren't included in the data or that had NA values. We will validate the other 4 assumptions for each subsequent model.

The fifth model, is a regression of the crime rate multiplied by the mix.  NEED MADELEINE'S INPUT HERE. 

For each model, we use the classic linear model assumptions: 

Assumption 1: Linear in Parameters
Assumption 2: Random (i.i.d) Sampling
Assumption 3: Multicollinearity
Assumption 4: Zero Conditional Mean/Exogeneity
Assumption 5: Homoskedasticity
Assumption 6: Normality of Variance

Assumption 1, linearity in parameters, holds, as each fit model has slope coefficients that are linear multipliers of the associated predictor variables. Assumption 2, random sampling, says that are data points must be independent and identically distributed. We have data for 97 of North Carolina's 100 counties (89 after remove NA values). While this represents something closer to the population of counties than a sample, we should be okay on the random sampling assumption if we assume that there is no pattern to the counties that weren't included in the data or that had NA values. We will validate the other 4 assumptions for each subsequent model.




### 4.1 Model 1

Causes of crime have been debated, but we suspect that density, tax per capita, and percent young male are strong predictors of crime.  The dependent variable, crime rate, has already been assessed, so we evaluate these three predictor variables.

Density:
```{r fig.height=3, fig.width=5}
summary(df_clean$density)
hist(df_clean$density,
     main="Densities for Individual Counties", 
     xlab= "Density", 
     ylab= "Number of Counties",
     breaks = 30)
```

The value of density ranges from approximately .00002 to 8.8 people per square mile, with a mean of 1.45. The distribution of county densities is right skewed, with most counties being sparse and a long tail of more populated counties. After reviewing the census data, it is logical to conclude that these numbers are in hundreds of people per square mile, but for consistency we will continue to use the people per square mile unit.   

Tax per Capita:
```{r fig.height=3, fig.width=5}
summary(df_clean$taxpc)
hist(df_clean$taxpc,
     main="Tax for Individual Counties", 
     xlab= "Tax per Capita", 
     ylab= "Number of Counties",
     breaks = 30)
```

The value of tax per capita ranges from 25.69 to 119.76.  Once again, we see a distribution that is right skewed, with revenue in most counties below the mean of 38.13. The maximum value is much higher than the next highest value.  Though this is an interesting note, evaluating the row, we have no reason to doubt this data point.

Percent Young Male:
```{r fig.height=3, fig.width=5}
summary(df_clean$pctymle)
hist(df_clean$pctymle,
     main="Young Males for Individual Counties", 
     xlab= "Percent Young Males", 
     ylab= "Number of Counties",
     breaks = 30)
```

The percent of young males ranges from 6.2 to 24.9 %.  Once again, we see a distribution that is right skewed, with revenue in most counties below the mean of 8.4 %. The skew of this distribution leads us to take the log of this variable within our model, to spread out the data in the lower end of the range.  Again, we see the maximum value is much higher than the next highest value, and again, we have no reason to doubt this data point.

Before we build our model, we review the matrix of scatterplots of crime rate and the three variables evaluated above to identify any potential collinearity, and validate assumption MLR.3, multicollinearity.
```{r}
vars <- c("crmrte", "density", "taxpc","pctymle")
suppressWarnings(scatterplotMatrix(df_clean[,vars], diagonal = "histogram"))
```

As we suspected, crime rate looks well predicted by each of the three primary variables selected as evidenced by the fairly strong positive slopes in the bivariate regressions in the scatterplot matrix.  Additionally, though density and taxpc appear to have a positive correlation, none of the variables are perfectly collinear with any of the others, validating the multicollinearity assumption.

With the evaluation of the variables complete, we build model 1, and evaluate the Cook's Distance for the residuals:
```{r fig.height=4, fig.width=5}
# Build Model 1
(model_1 = lm(crmrte ~ density + taxpc + log(pctymle), data = df_clean))
summary(model_1)$r.square
plot(model_1, which = 5)
```
We find one point that has a Cook's Distance greater than 1, Manteo county, but with no justification to remove it from the dataset, we simply note it. Of note, this county has the highest tax per capita, which could stem from its tourist destination status as the location of the Wright brothers' first flight.

Now that the model is built, we can validate assumption 4, the exogeneity assumption.  To do this, we check that the sum of the residuals is 0.
```{r}
round(sum(model_1$residuals * model_1$fitted.values), 15)
```
We find that the residuals sum to 0, validating assumption 4.

To validate assumption 5, homoskedasticity, we took a look at the residuals vs. fitted values plot and noted that the error range was relatively constant throughout the range of fitted values.  This was difficult to validate because we have fewer data points at the higher values of crime rate than the lower values of crime rate.

To validate assumption 6, the normality of the residuals, we looked at a Q-Q plot of the residuals, and noted the fairly straight line.

From the equation for model 1 (Equation 1), we can see that all of these model coefficients are positive, indicating that for an increase in density, taxpc, or pctymle, there is an associated increase in crime rate.

\[\tag{Equation 1}
crmrte = -0.0409 + 0.007 \cdot density + 0.0004 \cdot taxpc + 0.023 \cdot log(pctymle)
\]

The log transformation of pctymle masks the magnitude of the effect, but density has a larger effect than tax per capita.  

KIM: THIS WOULD BE A GOOD PLACE TO TALK ABOUT WHY WE SUSPECT THE EFFECTS ARE IN THE DIRECTION THEY ARE IN AND WHAT SORTS OF POLICIES WE MIGHT SUGGEST TO DETER CRIME.


### 4.2 Model 2

Model 2 includes west, polpc, prbarr, and prbconv in addtion to the three variables from Model 1.  During our EDA, we found that each of these had interesting correlations with the variable of interest, crime rate, leading to their inclusion.

We conducted a full EDA on each of the explanatory variables, but for the sake of space, a simple matrix plot of the additional variables, other than west, is shown below.

```{r warnings = FALSE}
vars <- c("west", "polpc", "prbarr", "prbconv","pctmin80")
suppressWarnings(scatterplotMatrix(df_clean[,vars], diag = "histogram"))
```
The matrix plot shows little correlation, and certainly no perfect multicollinearity, between the additional variables in this model.  One noteworthy observation is that pctmin80 appears correlated with west, which may absorb some of the effect.  To validate assumption 3, collinearity, we also checked the scatterplots of these variables against the original three included in model 1.  No perfect multicollinearity was found.

```{r fig.size=4, fig.width=5}
# Build Model 2
(model_2 = lm(crmrte ~ density + taxpc + log(pctymle) 
              + west + log(polpc) + prbarr + prbconv + pctmin80, 
              data = df_clean))
summary(model_2)$r.square
plot(model_2, which = 5)
```

Unsurprisingly, the $R^2$ increased from 0.64 to 0.79 with these additional 5 variables included. We also note that point 25 still has high leverage, just as in model 1.  Perhaps we should study that county a bit more closely.

We also check assumption 4, exogeneity, by summing the product of the residuals and fitted values and finding the sum of 0.
```{r}
round(sum(model_2$residuals * model_2$fitted.values), 15)
```
Assumptions 5 and 6 were validated for this model as they were for model 1.

Model 2, shown in the table in section 4.6 has positive coefficients for density, taxpc, pctymle, polpc, and pctmin80 indicating that crime rate increases and these variables increase. On the other hand, the coefficients for west, prbarr, and prbconv are negative, indicating that crime rate decreases as these increase.  

KIM: THIS WOULD BE A GOOD PLACE TO TALK ABOUT WHY WE SUSPECT THE EFFECTS ARE IN THE DIRECTION THEY ARE IN AND WHAT SORTS OF POLICIES WE MIGHT SUGGEST TO DETER CRIME.

### 4.3 Model 3

For model 3, in addition to the variables from model 2, we added the remainder of the variables that we did not find problematic: central, avgsen, prison.  These variables do not necessarily explain the crime rate well, but serve to show that model 2 gives a reasonable explanation of the observed crime rate. We excluded the urban variable because it is too closely related to density, as can be seen in this scatterplot:
```{r fig.height=4, fig.width=5}
plot(df_clean$urban , df_clean$density,
     main= "Urban Density",
     ylab= "Density (100 people per square mile)",
     xlab= "Urban")
```

We also excluded all of the wage variables because we cannot make any meaningful conclusions without a breakdown of what portions of each county are involved in each profession.

With that, we build model 3:
```{r fig.height=4, fig.width=5}
# Build Model 3
(model_3 = lm(crmrte ~ density + taxpc + pctymle + west + log(polpc) + prbarr + prbconv + pctmin80 + central + avgsen + prbpris, data = df_clean))
summary(model_3)$r.square
plot(model_3, which = 5)
```

We note that point 25 is still exhibiting a Cook's distance of greater than 1.

Assumptions 5 and 6 were validated for this model as they were for models 1 and 2.

This model, while interesting as an upper bound on what can reasonably be included in a model, should not be used to influence policy decisions.

### 4.4 Model 4
For this model, we included every variable available to us, simply to set an upper limit on the possible $R^2$.  The resulting model is not a parsimonious one, and as such, we should not use it.  However, it is interesting to note that the $R^2$ rises to 0.84, which is not much higher than model 3.
```{r fig.height=4, fig.width=5}
# Build Model 4
model_4 = lm(crmrte ~ density + taxpc + pctymle + west + log(polpc) + prbarr + prbconv + pctmin80 + central + avgsen + prbpris + urban + wcon + wtuc + wtrd + wfir + wser + wmfg + wfed + wsta + wloc, data = df_clean)
paste("The R.square is", round(summary(model_4)$r.square, 2))
plot(model_4, which = 5)
```

### 4.5 Model 5




```{r}
# Build Model 5
# model 5: the model 1 version of a model for this dependent variable - crmrate*mix
```

### 4.6 Model Summary
This is where we put our model summary table.
```{r, results='asis'}
stargazer(model_1, model_2, model_3, model_4, type = "latex", 
          report = "vc", # Don't report errors, since we haven't covered them
          title = "Linear Models Predicting Crime Rate",
          keep.stat = c("rsq", "n"),
          omit.table.layout = "n") # Omit more output related to errors
```

## 5. Omitted Variables

household earnings: we would expect coefficient on hh_earnings to be negative, since wealthier areas = less crime. We would expect correlation between household earnings and density to positive, because in cities people have higher salaries. Therefore, omitted variable bias is _negative_, and if we had household earnings, the fitted values for a given density value would likely be higher.

socioeconomic disparity:

unemployment rate: we would expect coefficient on unemployment rate to be positive, since more people without work = more people in desperate situations that lead to them breaking the law. We would expect correlation between unemployment and percent young male to be positive, since young men are most likely to be unemployed (I'm REALLY not sure about this one - if there's a better claim to be made with density, let's do it). Therefore, omitted variable bias is _positive_, and the fitted values would be lower for a given pctymle value if we had unemployment rate.

education level: We would expect coefficient on education level to be negative, as when people have more education, they probably have more job opportunities --> less likelihood to commit crime. We would expect coefficient between education level and density to be positive, since people tend to be more educated in urban areas. Therefore, omitted variable bias is _negative_, and the fitted values for a given value of density would likely be lower if we could control for education level.

## 6. Conclusion
- might be worth making a point about county as unit : might make sense since county likely determines different police/judicial jurisdictions, but certain elements in our model might not be consistent across whole county (i.e. density, tax rate in cities, etc.)
