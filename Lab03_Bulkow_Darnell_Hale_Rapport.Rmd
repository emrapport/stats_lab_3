---
title: "Lab 3: Reducing Crime"
subtitle: "w203 Summer 2018"
author: "Madeleine Bulkow, Kim Darnell, Alla Hale, Emily Rapport"
date: \today
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(stargazer)
# Import car package
library(car)
```

## 1. Introduction
As advisees to political campaigns for statewide office in North Carolina, we believe that the crime rate across the state should be of central concern to any candidate.  Local governments desire to control the crime rate, and rigorous data analysis is needed to understand the role of crime in different parts of the state. This report examines the available crime data and attempts to answer the following research question: What variables are associated with crime rates across counties in North Carolina?  Based on this analysis, we generate several policy suggestions applicable to government officials in North Carolina for the late 1980s.

## 2. Data Definitions and Data Cleaning
The data analyzed in this report were collected as part of a multi-year study on crime by Cornwell and Trumball, originally published in 1994. The data include factors related to crime, demographics, and the economy for 90 of the 100 counties in North Carolina. For reasons of access, this report will focus exculsively on the data from 1987. 
 
The dataset includes the following variables, which we present with definitions and assumptions:

*county*: integer code representing which county the row represents. We received the data with these identifier codes in place of county names, so we cannot identify the individual counties in the dataset.

*year*: 1987 for all data points. 

*crmrte*: ratio of crimes permitted to population, taken from the FBI's Uniform Crime Reports.

*prbarr*: ratio of arrests to offenses, taken from the FBI's Uniform Crime Reports.

*prbconv*: ratio of convictions to arrests. Arrest data is taken from the FBI's Uniform Crime Reports, while conviction data is taken from the North Carolina Department of Correction.

*prbpris*: ratio of prison sentences to convictions, taken from the North Carolina Department of Correction.

*avgsen*: average prison sentence in days, which we believe is taken from the North Carolina Department of Correction.

*polpc*: police per capita, computed using the FBI's police agency employee counts.

*density*: people per square mile

*taxpc*: tax revenue per capita. 

*west*: indicator code specifying whether county is in Western North Carolina (1 if yes, 0 if no).

*central*: indicator code specifying whether county is in Central North Carolina (1 if yes, 0 if no).

*urban*: indicator code specifying whether county is urban, defined by whether the county is in a Standard Metropolitan Statistical Area as defined by the US Census. 

*pctmin80*: percentage of population that belongs to minority racial group, as taken by the 1980 US Census.

*mix*: ratio of face-to-face offenses to other offenses.

*pctymle*: percent young male, defined as proportion of population that is male between the ages of 15 and 24, as taken by US Census data. 

The remaining variables represent weekly wages in particular industries, as provided by the North Carolina Employment Security Commission:
- *wcon*: construction
- *wtuc*: transit, utilities, and communication
- *wtrd*: wholesale, retail trade
- *wfir*: finance, insurance, real estate
- *wser*: service industry
- *wmfg*: manufacturing
- *wfed*: federal employees
- *wsta*: state employees
- *wloc*: local government employees
 
We start by evaluating the available data, cleaning it by removing anomolous values, and perhaps transforming the data.  
```{r}
# Import the data
df = read.csv("crime_v2.csv")
#summary(df)
```

In the original dataset, there are several variables, including *prbarr*, *prbpris*, and *pctymle* that represent probabilities and are given as decimal values between 0-1. To facilitate comparing the coefficients for these variables more easily with other numerical values, we converted them to percentages between 0-100.  We note that there is one county, Madison County (FIPS code 115), for which the *prbarr* value post-conversion is greater than 100%. This could reflect an error in data gathering or recording, but it may also reflect that it is common for indviduals in this county to be arrested with greater frequency than they commit specific offenses.

In the case of *prbconv*, several of the original values are greater than 1. Although this may seem anomalous, it reflects the fact that the "probablity of conviction" is more effectively described as a ratio of the number of convictions per arrest, rather than as a probability of being convicted following arrest. Given that one might not be arrested for all crimes that one is subsequently convicted of, it makes sense that these numbers have a greater range than a traditional probabilities.

The variable *mix* also appears as values between 0-1 in the original dataset.  We converted the values for this variable to percentages to make their scale more consistent with the rest of the data.

To facilitate discussion of the variable *polpc*, we converted it from number of police per capita in a county to number of police per 1000 residents of a county.  That is, it is simply clearer to say, "There are 4 police officers per 1000 residents" than "There is .004 of a police officer per resident".

In the original dataset, the values for Wilkes Country (FIPS code 193) are given twice.  We removed one. In addition, there were six rows in that had no values for any variable. We removed all of these.

Data were not provided for the following counties (FIPS county codes are provide in parentheses): Camden (29), Carteret (31), Clay (43), Gates (73), Graham (75), Hyde (95), Jones (103), Mitchell (121), Tyrrell (177), and Yancey (199).  We do not know why these cases were omitted from the original dataset, nor can we say the extent to which the omission of 1/10 counties across the state might affect the effectiveness of our recommendations. However, a review of 2012 population estimates for the omitted counties indicate that 9/10 are ranked between 86-100 of the 100 counties in overall population. The remaining omitted county is ranked 37th overall in population in the state.  The generally low population rates for the omitted counties may indicate that there was insufficient crime data to include them in the dataset.

```{r}
# Clean the data

## NOTE FROM ALLA: This is just what I did to clean the data.  I am sure this can be done in a more efficient way.  Please just let me know what the final df is called so that I can update it in my models.
df_calc <- df

# Convert the prbarr, prbpris, and pctymle variables from decimals to percentages
df_calc$prbarr <- df$prbarr * 100
df_calc$prbpris <- df$prbpris * 100
df_calc$pctymle <- df$pctymle * 100

# Convert the mix variable from decimals to percentage
df_calc$mix <- df$mix * 100

# Convert the polpc variable from decimals to number of police per 1000 people
df_calc$polpc <- df$polpc * 1000

# Convert the prbconv variable from integer to numeric
df_calc$prbconv <- as.numeric(levels(df$prbconv)[df$prbconv])

#summary(df_calc)

#remove row 89, which is a duplicate of row 88 (Madison County, FIPS 193)
df_clean <- df_calc[-c(89), ]

#remove rows with no data (i.e., all NA values)
df_clean <- df_clean[-c(91:97), ]

#remove 
#df_clean <-df_calc[with(df_calc, prbarr <= 100 & wser <= 2000),]
```

##3. Building Models
Our central goal for this analysis is to determine what variables are most associated with crime across the state of North Carolina. For this reason, we will  use the *crmrte* variable as the outcome variable for our models. To begin, we examine our outcome variable.

```{r}
summary(df_clean$crmrte)
length(df_clean$crmrte)
```

The value of *crmrte* ranges from approximately .6% to 9.9%, with a mean of approximately 3.4%. There are 90 total cases and no missing cases. A histogram of the data, shown below, reveals that the crime rate data are positively skewed, with the majority of counties having a crime rate between 1-4%.  The extended right tail indicates that a few counties have substantially higher crime rates, with some between 8-10%.

```{r fig.height=3, fig.width=5}
hist(df_clean$crmrte, 
     main="County Crime Rates in 1987 North Carolina", 
     xlab= "Crimes Committed per Person", 
     ylab= "Number of Counties")
```


## 4. The Models

We will engage the model building process in five stages, resulting in five separate models.  

The first four models are linear regressions of crime rate against an increasing numbers of predictive variables.  Model 1 includes only the variables we believe to be the main predictors of crime rate: population density (*density*), tax per capita (*taxpc*), and percentage of young males in the population (*pctymle*).  Model 2 includes the factors from Model 1 as well as several others that we believe contribute meaningfully to crime rate, including location in the state, the number of police per 1000 residents (*polpc*), the probability of being arrested (*prbarr*), and the probability of being convicted if arrested (*prbconv*).  Model 3 builds on Model 2 by adding information about the percentage of minorties (*pctmin80*), the probability of getting a prison sentence (*prbpris*), and the average length of sentence (*avgsen*).  In Model 4, we include all available variables, including those of questionable merit.  

For each of these models, we intend a classic linear model with the following assumptions: Assumption 1, linearity in parameters, holds, as each fit model has slope coefficients that are linear multipliers of the associated predictor variables. Assumption 2, random sampling, says that are data points must be independent and identically distributed. We have data for 97 of North Carolina's 100 counties (89 after remove NA values). While this represents something closer to the population of counties than a sample, we should be okay on the random sampling assumption if we assume that there is no pattern to the counties that weren't included in the data or that had NA values. We will validate the other 4 assumptions for each subsequent model.

The fifth model, is a regression of the crime rate multiplied by the mix.  NEED MADELEINE'S INPUT HERE.  

### 4.1 Model 1

Causes of crime have been debated, but we suspect that density, tax per capita, and percent young male are strong predictors of crime.  The dependent variable, crime rate, has already been assessed, so we evaluate these three predictor variables.

Density:
```{r fig.height=3, fig.width=5}
summary(df_clean$density)
hist(df_clean$density,
     main="Densities for Individual Counties", 
     xlab= "Density", 
     ylab= "Number of Counties",
     breaks = 30)
```

The value of density ranges from approximately .00002 to 8.8 people per square mile, with a mean of 1.45. The distribution of county densities is right skewed, with most counties being sparse and a long tail of more populated counties. After reviewing the census data, it is logical to conclude that these numbers are in hundreds of people per square mile, but for consistency we will continue to use the people per square mile unit.   

Tax per Capita:
```{r fig.height=3, fig.width=5}
summary(df_clean$taxpc)
hist(df_clean$taxpc,
     main="Tax for Individual Counties", 
     xlab= "Tax per Capita", 
     ylab= "Number of Counties",
     breaks = 30)
```

The value of tax per capita ranges from 25.69 to 119.76.  Once again, we see a distribution that is right skewed, with revenue in most counties below the mean of 38.13. The maximum value is much higher than the next highest value.  Though this is an interesting note, evaluating the row, we have no reason to doubt this data point.

Percent Young Male:
```{r fig.height=3, fig.width=5}
summary(df_clean$pctymle)
hist(df_clean$pctymle,
     main="Young Males for Individual Counties", 
     xlab= "Percent Young Males", 
     ylab= "Number of Counties",
     breaks = 30)
```

The percent of young males ranges from 6.2 to 24.9 %.  Once again, we see a distribution that is right skewed, with revenue in most counties below the mean of 8.4 %. Again, we see the maximum value is much higher than the next highest value, and again, we have no reason to doubt this data point.

Before we build our model, we review the matrix of scatterplots of crime rate and the three variables evaluated above to identify any potential collinearity.
```{r}
vars <- c("crmrte", "density", "taxpc","pctymle")
suppressWarnings(scatterplotMatrix(df_clean[,vars], diagonal = "histogram"))
```

As we suspected, crime rate looks well predicted by each of the three primary variables selected as evidenced by the fairly strong positive slopes in the bivariate regressions in the scatterplot matrix.  Additionally, though density and taxpc appear to have a positive correlation, none of the variables are collinear with any of the others.

With the evaluation of the variables complete, we build model 1, and evaluate the Cook's Distance for the residuals:
```{r fig.height=4, fig.width=5}
# Build Model 1
(model_1 = lm(crmrte ~ density + taxpc + pctymle, data = df_clean))
summary(model_1)$r.square
plot(model_1, which = 5)
```
We find one point that has a Cook's Distance greater than 1, but with no justification to remove it from the dataset, we simply note it. 

### 4.2 Model 2

Model 2 includes west, polpc, prbarr, and prbconv in addtion to the three variables from Model 1.  During our EDA, we found that each of these had interesting correlations with the variable of interest, crime rate.

We conducted a full EDA on each of the explanatory variables, but for the sake of space, a simple matrix plot of the additional variables, other than west, is shown below.
```{r warnings = FALSE}
vars <- c("polpc", "prbarr", "prbconv","pctmin80")
suppressWarnings(scatterplotMatrix(df_clean[,vars], diagonal = "histogram"))
```
The matrix plot shows little correlation between most of the additional variables in this model.

```{r fig.size=4, fig.width=5}
# Build Model 2
# model 2: other things that are explanatory but maybe questionable: west, polpc, arrest/conviction, ppctmin80. 
(model_2 = lm(crmrte ~ density + taxpc + pctymle 
              + west + log(polpc) + prbarr + prbconv + pctmin80, 
              data = df_clean))
summary(model_2)$r.square
plot(model_2, which = 5)
```

Interestingly, the $R^2$ increased from 0.63 to 0.79 with these additional 5 variables included.

### 4.3 Model 3
```{r fig.height=4, fig.width=5}
# Build Model 3
#model 3: not necessarily explanatory, but not problematic: central, avgsen, prison.
(model_3 = lm(crmrte ~ density + taxpc + pctymle + west + log(polpc) + prbarr + prbconv + pctmin80 + central + avgsen + prbpris, data = df_clean))
summary(model_3)$r.square
plot(model_3, which = 5)
```
### 4.4 Model 4
```{r fig.height=4, fig.width=5}
# Build Model 4
# model 4: kitchen sink. urban, wage.
(model_4 = lm(crmrte ~ density + taxpc + pctymle + west + log(polpc) + prbarr + prbconv + pctmin80 + central + avgsen + prbpris + urban + wcon + wtuc + wtrd + wfir + wser + wmfg + wfed + wsta + wloc, data = df_clean))
summary(model_4)$r.square
plot(model_4, which = 5)
```

### 4.5 Model 5
```{r}
# Build Model 5
# model 5: the model 1 version of a model for this dependent variable - crmrate*mix
```

### 4.2 Model Summary
This is where we put our model summary table.
```{r, results='asis'}
stargazer(model_1, model_2, model_3, model_4, type = "latex", 
          report = "vc", # Don't report errors, since we haven't covered them
          title = "Linear Models Predicting Crime Rate",
          keep.stat = c("rsq", "n"),
          omit.table.layout = "n") # Omit more output related to errors
```

## 5. Omitted Variables

## 6. Conclusion
- might be worth making a point about county as unit : might make sense since county likely determines different police/judicial jurisdictions, but certain elements in our model might not be consistent across whole county (i.e. density, tax rate in cities, etc.)
